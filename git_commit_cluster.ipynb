{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gitpython==3.1.41\n",
    "!pip install langchain-core==0.2.1\n",
    "!pip install langchain-openai==0.1.7\n",
    "!pip install openai==1.30.3\n",
    "# !pip install faiss-cpu==1.7.3\n",
    "!pip install faiss-gpu==1.7.2\n",
    "!pip install aiofiles==23.1.0\n",
    "!pip install python-dotenv==1.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "repo_path: /home/hchen/src/github.com/OpenDevin\n",
      "faiss_index_path: /home/hchen/src/faiss/faiss_index\n",
      "FAISS_NO_AVX2: true\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_community.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "# Set the storage path\n",
    "storage_path = os.environ.get(\"GIT_STORAGE_PATH\", \"/tmp\")\n",
    "faiss_index_path = storage_path + \"/faiss_index\"\n",
    "repo_path = os.environ.get('GIT_REPO_PATH')\n",
    "FAISS_NO_AVX2 = os.environ.get('FAISS_NO_AVX2', 'true')\n",
    "print('repo_path:', repo_path)\n",
    "print('faiss_index_path:', faiss_index_path)\n",
    "print('FAISS_NO_AVX2:', FAISS_NO_AVX2)\n",
    "\n",
    "store = LocalFileStore(\"./cache/\")\n",
    "#embeddings_model = OpenAIEmbeddings()\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "underlying_embeddings_model = HuggingFaceEmbeddings(model_name=model_name)\n",
    "\n",
    "embeddings = CacheBackedEmbeddings.from_bytes_store(\n",
    "    underlying_embeddings_model, store, namespace=\"embeddings\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import git\n",
    "from typing import Iterator\n",
    "from langchain_core.document_loaders import BaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "class GitRepoCommitsLoader(BaseLoader):\n",
    "    \"\"\"\n",
    "    A custom loader for git repository commits that extracts commit messages and diffs as documents.\n",
    "\n",
    "    Attributes:\n",
    "        repo_path (str): The path to the git repository.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, repo_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Initializes the GitRepoCommitsLoader with the specified repository path.\n",
    "\n",
    "        Args:\n",
    "            repo_path (str): The path to the git repository.\n",
    "        \"\"\"\n",
    "        self.repo_path = repo_path\n",
    "\n",
    "    def lazy_load(self) -> Iterator[Document]:\n",
    "        \"\"\"\n",
    "        Lazily loads the commit messages and diffs from the git repository.\n",
    "\n",
    "        Yields:\n",
    "            Iterator[Document]: An iterator of Document objects containing commit messages and diffs.\n",
    "        \"\"\"\n",
    "        repo = git.Repo(self.repo_path)\n",
    "        all_commits = list(repo.iter_commits())\n",
    "        print('commits:', len(all_commits))\n",
    "        # use a subset\n",
    "        commits = all_commits[10:300]\n",
    "        for commit in commits:\n",
    "            commit_message = commit.message\n",
    "            commit_diff = commit.diff(create_patch=True)\n",
    "\n",
    "            diff_texts = []\n",
    "            for diff in commit_diff:\n",
    "                diff_texts.append(diff.diff.decode('utf-8'))\n",
    "\n",
    "            commit_diff_text = '\\n'.join(diff_texts)\n",
    "            content = f\"Commit Message:\\n{commit_message}\\n\\nCommit Diff:\\n{commit_diff_text}\"\n",
    "\n",
    "            yield Document(page_content=content,\n",
    "                           metadata={\n",
    "                               \"commit_hash\": commit.hexsha,\n",
    "                               \"author\": commit.author.name,\n",
    "                               \"date\": commit.committed_datetime.isoformat()\n",
    "                           })\n",
    "\n",
    "\n",
    "loader = GitRepoCommitsLoader(repo_path=repo_path)\n",
    "documents = list(loader.lazy_load())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load and index 290 documents into vectorstore /home/hchen/src/faiss/faiss_index\n",
      "Loaded 290 documents\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "def load_and_index_git_repository(documents):\n",
    "    print(f'load and index {len(documents)} documents into vectorstore {faiss_index_path}')\n",
    "    docs = [] \n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=4000, chunk_overlap=200)\n",
    "\n",
    "    print(f\"Loaded {len(documents)} documents\")\n",
    "    for d in documents:\n",
    "        # reset the metadata\n",
    "        ds = []\n",
    "        ds.append(d)\n",
    "        splitted_doc = text_splitter.split_documents(ds)\n",
    "        pages = 0\n",
    "        for s in splitted_doc:\n",
    "            s.metadata['page'] = pages\n",
    "            pages += 1\n",
    "            s.metadata['commit_hash'] = d.metadata['commit_hash']\n",
    "            s.metadata['author'] = d.metadata['author']\n",
    "            s.metadata['date'] = d.metadata['date']          \n",
    "            docs.append(s)\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    vectorstore.save_local(faiss_index_path)\n",
    "\n",
    "    return vectorstore, documents, docs\n",
    "\n",
    "vectordb, documents, docs = load_and_index_git_repository(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'commit_hash': '8d79c3edbc3ef0c8a41e1bab823279c335037e47', 'author': 'Yizhe Zhang', 'date': '2024-06-02T06:38:09+00:00', 'page': 0}\n",
      "{'commit_hash': '1bdf8752e6459987d0ed3554a8b1b4007303c760', 'author': 'Yufan Song', 'date': '2024-06-08T19:04:43+00:00', 'page': 227}\n",
      "{'commit_hash': 'a97d0767e90934d0dcc82e281e8da76af220a937', 'author': 'tobitege', 'date': '2024-06-08T21:02:27+00:00', 'page': 227}\n",
      "{'commit_hash': '68d9ad61cf59724c761c4f700d4b7be25690f320', 'author': 'yueqis', 'date': '2024-06-08T16:54:54+00:00', 'page': 228}\n"
     ]
    }
   ],
   "source": [
    "def similarity_search(vectorstore, query, score=0.8):\n",
    "    results = vectorstore.similarity_search_with_relevance_scores(query)\n",
    "    ret = []\n",
    "    for i in results:\n",
    "        doc = i[0]\n",
    "        relevance_score = i[1]\n",
    "        # print('relevance_score:', relevance_score)\n",
    "        if relevance_score > score:\n",
    "            ret.append(doc)\n",
    "    return ret\n",
    "\n",
    "query = \"custom git commit\"\n",
    "results = similarity_search(vectordb, query, score=0.2)\n",
    "\n",
    "for result in results:\n",
    "    print(result.metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_doc: 290\n",
      "orig_docs: 116410\n"
     ]
    }
   ],
   "source": [
    "orig_doc = documents\n",
    "orig_docs = docs\n",
    "print('orig_doc:', len(orig_doc))\n",
    "print('orig_docs:', len(orig_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/116410: 4 similar documents\n",
      "518/116410: 8 similar documents\n",
      "520/116410: 5 similar documents\n",
      "524/116410: 7 similar documents\n",
      "9982/116410: 7 similar documents\n",
      "10257/116410: 7 similar documents\n",
      "10533/116410: 7 similar documents\n",
      "13548/116410: 9 similar documents\n",
      "13550/116410: 5 similar documents\n",
      "13554/116410: 7 similar documents\n",
      "18677/116410: 8 similar documents\n",
      "18679/116410: 5 similar documents\n",
      "18683/116410: 7 similar documents\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m counter \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m query \u001b[38;5;241m=\u001b[39m doc\u001b[38;5;241m.\u001b[39mpage_content\n\u001b[0;32m----> 7\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mvectordb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimilarity_search_with_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m similar_results \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain_community/vectorstores/faiss.py:392\u001b[0m, in \u001b[0;36mFAISS.similarity_search_with_score\u001b[0;34m(self, query, k, filter, fetch_k, **kwargs)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimilarity_search_with_score\u001b[39m(\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    373\u001b[0m     query: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    378\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Tuple[Document, \u001b[38;5;28mfloat\u001b[39m]]:\n\u001b[1;32m    379\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return docs most similar to query.\u001b[39;00m\n\u001b[1;32m    380\u001b[0m \n\u001b[1;32m    381\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[38;5;124;03m        L2 distance in float. Lower score represents more similarity.\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 392\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_embed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    393\u001b[0m     docs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msimilarity_search_with_score_by_vector(\n\u001b[1;32m    394\u001b[0m         embedding,\n\u001b[1;32m    395\u001b[0m         k,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    399\u001b[0m     )\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m docs\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain_community/vectorstores/faiss.py:155\u001b[0m, in \u001b[0;36mFAISS._embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_embed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m    154\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function, Embeddings):\n\u001b[0;32m--> 155\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_function(text)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain/embeddings/cache.py:194\u001b[0m, in \u001b[0;36mCacheBackedEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Embed query text.\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \n\u001b[1;32m    184\u001b[0m \u001b[38;5;124;03mBy default, this method does not cache queries. To enable caching, set the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    The embedding for the given text.\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_embedding_store:\n\u001b[0;32m--> 194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munderlying_embeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    196\u001b[0m (cached,) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_embedding_store\u001b[38;5;241m.\u001b[39mmget([text])\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cached \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain_community/embeddings/huggingface.py:104\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_query\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, text: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mfloat\u001b[39m]:\n\u001b[1;32m     96\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute query embeddings using a HuggingFace transformer model.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;124;03m        Embeddings for the text.\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/langchain_community/embeddings/huggingface.py:91\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.embed_documents\u001b[0;34m(self, texts)\u001b[0m\n\u001b[1;32m     89\u001b[0m     sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer\u001b[38;5;241m.\u001b[39mstop_multi_process_pool(pool)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 91\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/sentence_transformers/SentenceTransformer.py:188\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m    187\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m--> 188\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[1;32m    192\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "docs = orig_docs\n",
    "counter = 0\n",
    "for doc in docs:\n",
    "    counter += 1\n",
    "    \n",
    "    query = doc.page_content\n",
    "    results = vectordb.similarity_search_with_score(query=query, k=10)\n",
    "    \n",
    "    similar_results = []\n",
    "    for result in results:\n",
    "        if type(result) is tuple: \n",
    "            doc = result[0]\n",
    "            score = result[1]\n",
    "            if score > 0.7:\n",
    "                similar_results.append(doc)\n",
    "    if len(similar_results) > 0:\n",
    "        print(f'{counter}/{len(docs)}: {len(similar_results)} similar documents')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
